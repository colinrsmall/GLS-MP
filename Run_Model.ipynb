{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Run Model",
      "provenance": [],
      "collapsed_sections": [
        "lOtRYivaI36K",
        "57VGjlCEI36N"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinrsmall/GLS-MP/blob/master/Run_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh1fTA2NI358",
        "colab_type": "text"
      },
      "source": [
        "# MMS SITL Ground Loop: Running the GLS MP Model\n",
        "This notebook runs the `mp-dl-unh` GLS Magnetopause model to make predictions. The end result is a CSV file with model selections. This notebook and the model can be run using Level-2 (L2) data, which is publicly available at the [SDC](https://lasp.colorado.edu/mms/sdc/public/), but operationally is ran using SITL- or Quick Look (QL)-level data, which is not public and requires a username and password.\n",
        "\n",
        "<span style=\"font-size:larger;\">**Contents**</span>\n",
        "* [Front Matter](#front_matter)\n",
        "* [Setting Up](#setting_up)\n",
        "* [Download Data](#download_data)\n",
        "  * [FGM](#download_fgm)\n",
        "  * [EDP](#download_edp)\n",
        "  * [DIS](#download_dis)\n",
        "  * [DES](#download_des)\n",
        "  * [Combine Dataframes](#combine_dataframes)\n",
        "* [Run the Model](#run_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM4P2GofI35-",
        "colab_type": "text"
      },
      "source": [
        "<a id='front_matter'></a>\n",
        "## Front Matter\n",
        "This section defines the packages to import, data and model directories, SDC log-in credentials, and model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1tQwg45JE_J",
        "colab_type": "code",
        "outputId": "4d5fc9f0-2cc9-4775-8444-74b81fa102d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!pip install nasa-pymms"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nasa-pymms in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (4.41.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (1.18.5)\n",
            "Requirement already satisfied: cdflib in /usr/local/lib/python3.6/dist-packages (from nasa-pymms) (0.3.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->nasa-pymms) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->nasa-pymms) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->nasa-pymms) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->nasa-pymms) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.1->nasa-pymms) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.1->nasa-pymms) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.1->nasa-pymms) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.1->nasa-pymms) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.1->nasa-pymms) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ksUlD4yYCja",
        "colab_type": "code",
        "outputId": "ce013450-954e-4977-ac1a-8fa7edf7ba7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir /.pymmsrc/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/.pymmsrc/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPnxTxRZsDjQ",
        "colab_type": "text"
      },
      "source": [
        "If you want to use SITL-level data and you have SDC login credentials, you can enter them below under [SDCLOGIN]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sag8EDtCX_ri",
        "colab_type": "code",
        "outputId": "996cccc4-851c-4d79-ecee-b7d78fe55a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /.pymmsrc/pymmsrc\n",
        "; Example pymms configuration file. To make the configuration active, \n",
        "; copy this version to \"config.ini\" and edit.\n",
        "\n",
        "[DIRS]\n",
        "; data_root : directory in which all MMS files are stored.\n",
        "; dropbox_root : holding directory where newly generated files are\n",
        ";   placed for file validation purposes before being moved into the\n",
        ";   data root.\n",
        "; mirror_root : is the root of a local mirror of the SDC where some\n",
        ";   or all files are rsynced\n",
        "data_root = root/mms/data/\n",
        "dropbox_root = /content/chunk_files/\n",
        "mirror_root = None\n",
        "\n",
        "[SDCLOGIN]\n",
        "; Log-in credentials to the SDC\n",
        "username = \n",
        "password = "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /.pymmsrc/pymmsrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuXoU5L9I35-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pymms\n",
        "from pymms.util.tai import utc2tai\n",
        "from pymms.sdc import mrmms_sdc_api as api\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.constants\n",
        "from cdflib import cdfread, epochs\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import sklearn # Required to open scaler.sav file\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Disables Tensorflow debugging information\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xjdMtrFsLOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "a34a6d2d-9852-496d-83f5-b519b0d0d1f6"
      },
      "source": [
        "!mkdir model\n",
        "!wget https://zenodo.org/record/3884266/files/model_weights.h5?download=1 -O model/model_weights.h5\n",
        "!wget https://zenodo.org/record/3884266/files/scaler.sav?download=1 -O model/scaler.sav"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "--2020-06-12 22:41:43--  https://zenodo.org/record/3884266/files/model_weights.h5?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 NOT FOUND\n",
            "2020-06-12 22:41:44 ERROR 404: NOT FOUND.\n",
            "\n",
            "--2020-06-12 22:41:44--  https://zenodo.org/record/3884266/files/scaler.sav?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 NOT FOUND\n",
            "2020-06-12 22:41:45 ERROR 404: NOT FOUND.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWhzkewTI36C",
        "colab_type": "text"
      },
      "source": [
        "The `data_root` is the directory in which all data files are downloaded. It, as well as your MMS log-in credentials, can be set more permanently in the configuration file within pymms. The `dropbox_root` is where the new model predictions generated by this notebook will be saved, and `model_root` is just the mms-sitl-ground-loop package directory where this notebook and the model parameters are kept. Here, we assume that `model_root` is in the current working directory, which [may not be true](https://github.com/ipython/ipython/issues/10123)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlExbcL8I36C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_root = '/content/model'\n",
        "if not os.path.isfile(os.path.join(model_root, 'model.model')):\n",
        "    raise ValueError('Could not automatically determine the model root.')\n",
        "\n",
        "# Paths\n",
        "data_path_root = Path(pymms.config['data_root']).expanduser().absolute().resolve()\n",
        "dropbox_root = data_path_root / 'mp_dl_unh_predictions/'\n",
        "model_root = Path(model_root).expanduser().absolute().resolve()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZSlLSYzI36E",
        "colab_type": "text"
      },
      "source": [
        "Here, we define the spacecraft, data rate mode, data level, and interval in which to make predictions. For the model to perform accurately, `level='sitl'`; however, the SITL-level data is not publicly available and requires an SDC username and password. If you do not have a password for the SDC, you can change to `level='l2'` to use the public database.\n",
        "\n",
        "The interval can be specified either by orbit number or by `datetime.datetime` object. Normally, predictions are made using the start time of the first sub-region of interest (SROI) and the end time of the last SROI. If the interval is an orbit number, the SROI time intervals are obtained automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TVGSYLsI36F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data from orbit 1067 SROI1\n",
        "sc = 'mms1'\n",
        "level = 'sitl' # 'sitl' (private) or 'l2' (public)\n",
        "# start_interval = 1067\n",
        "# end_interval = 1067\n",
        "start_interval = datetime.datetime(2017, 10, 1)\n",
        "end_interval = datetime.datetime(2017, 10, 31, 23, 59, 59)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzNsq0kgI36H",
        "colab_type": "text"
      },
      "source": [
        "Check the user inputs and define static inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlhdIYOJI36I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SITL data is available in the fast-survey region of the orbit.\n",
        "# For many instruments, fast- and slow-survey data are combined into a single survey product\n",
        "mode = 'srvy'\n",
        "\n",
        "# This script works only for 'sitl' and 'l2' data\n",
        "if level not in ('sitl', 'l2'):\n",
        "    raise ValueError('Level must be either \"sitl\" or \"l2\".')\n",
        "\n",
        "# If an orbit number is given, \n",
        "if isinstance(start_interval, int):\n",
        "    sroi = api.mission_events('sroi', start_interval, start_interval, sc=sc)\n",
        "    start_date = sroi['tstart'][0]\n",
        "    end_date = sroi['tend'][-1]\n",
        "else:\n",
        "    start_date = start_interval\n",
        "    end_date = end_interval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOtRYivaI36K",
        "colab_type": "text"
      },
      "source": [
        "<a id='setting_up'></a>\n",
        "## Setting Up\n",
        "Use the [SDC API](https://lasp.colorado.edu/mms/sdc/public/about/how-to/) to search for available files within the desired time interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9IDchdzI36K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an interface to the SDC\n",
        "mms = api.MrMMS_SDC_API(sc=sc, mode=mode, start_date=start_date, end_date=end_date)\n",
        "\n",
        "# Ensure that the log-in information is there.\n",
        "#   - If the config file was already set, this step is redundant.\n",
        "mms._data_root = pymms.config['data_root']\n",
        "if mode == 'sitl':\n",
        "    mms._session.auth(pymms.config['username'], pymms.config['password'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57VGjlCEI36N",
        "colab_type": "text"
      },
      "source": [
        "<a id='download_data'></a>\n",
        "## Download and Read Data\n",
        "Start downloading data. We use two helper functions: `read_cdf_vars` to read variable data from CDF files and `quality_factor` to compute a burst trigger quality values as in Section 3.3 of [Phan et al. 2015](http://dx.doi.org/10.1007/s11214-015-0150-2).\n",
        "\n",
        "The data used here is from the [AFG](http://dx.doi.org/10.1007/s11214-014-0057-3), EDP (from [SDP](http://dx.doi.org/10.1007/s11214-014-0116-9) and [ADP](http://dx.doi.org/10.1007/s11214-014-0115-x)), [DIS, and DES](http://dx.doi.org/10.1007/s11214-016-0245-4) instruments. CDF files are download, data is read and stored as Pandas data frames. Additional metafeatures are calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9rIqHswI36N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_cdf_vars(cdf_files, cdf_vars, epoch='Epoch'):\n",
        "    '''\n",
        "    Read variables from CDF files into a data frame\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    cdf_files : str or list\n",
        "        CDF files to be read\n",
        "    cdf_vars : str or list\n",
        "        Names of the variables to be read\n",
        "    epoch : str\n",
        "        Name of the time variable that serves as the data frame index\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    out : `pandas.DataFrame`\n",
        "        The data. If a variable is 2D, \"_#\" is appended, where \"#\"\n",
        "        increases from 0 to var.shape[1]-1.\n",
        "    '''\n",
        "    tepoch = epochs.CDFepoch()\n",
        "    if isinstance(cdf_files, str):\n",
        "        cdf_files = [cdf_files]\n",
        "    if isinstance(cdf_vars, str):\n",
        "        cdf_vars = [cdf_vars]\n",
        "    if epoch not in cdf_vars:\n",
        "        cdf_vars.append(epoch)\n",
        "    \n",
        "    out = []\n",
        "    for file in cdf_files:\n",
        "        file_df = pd.DataFrame()\n",
        "        cdf = cdfread.CDF(file)\n",
        "        \n",
        "        for var_name in cdf_vars:\n",
        "            # Read the variable data\n",
        "            data = cdf.varget(var_name)\n",
        "            if var_name == epoch:\n",
        "                data = tepoch.to_datetime(data, to_np=True)\n",
        "            \n",
        "            # Store as column in data frame\n",
        "            if data.ndim == 1:\n",
        "                file_df[var_name] = data\n",
        "                \n",
        "            # 2D variables get \"_#\" appended to name for each column\n",
        "            elif data.ndim == 2:\n",
        "                for idx in range(data.shape[1]):\n",
        "                    file_df['{0}_{1}'.format(var_name, idx)] = data[:,idx]\n",
        "                    \n",
        "            # 3D variables gets reshaped to 2D and treated as 2D\n",
        "            # This includes variables like the pressure and temperature tensors\n",
        "            elif data.ndim == 3:\n",
        "                dims = data.shape\n",
        "                data = data.reshape(dims[0], dims[1]*dims[2])\n",
        "                for idx in range(data.shape[1]):\n",
        "                    file_df['{0}_{1}'.format(var_name, idx)] = data[:,idx]\n",
        "            else:\n",
        "                print('cdf_var.ndims > 3. Skipping. {0}'.format(var_name))\n",
        "                continue\n",
        "        \n",
        "        # Close the file\n",
        "        cdf.close()\n",
        "        \n",
        "        # Set the epoch variable as the index\n",
        "        file_df.set_index(epoch, inplace=True)\n",
        "        out.append(file_df)\n",
        "    \n",
        "    # Concatenate all of the file data\n",
        "    out = pd.concat(out)\n",
        "    \n",
        "    # Check that the index is unique\n",
        "    # Some contiguous low-level data files have data overlap at the edges of the files (e.g., AFG)\n",
        "    if not out.index.is_unique:\n",
        "        out['index'] = out.index\n",
        "        out.drop_duplicates(subset='index', inplace=True, keep='first')\n",
        "        out.drop(columns='index', inplace=True)\n",
        "    \n",
        "    # File names are not always given in order, so sort the data\n",
        "    out.sort_index(inplace=True)\n",
        "    return out      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPQKFuCkI36Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rename_df_cols(df, old_col, new_cols):\n",
        "    '''\n",
        "    Each column of a multi-dimensional CDF variable gets stored as\n",
        "    its own independent column in the DataFrame, with \"_#\" appended\n",
        "    to the original variable name to indicate which column index\n",
        "    the column was taken from. This function renames those columns.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    df : `pandas.DataFrame`\n",
        "        DataFrame for which the columns are to be renamed\n",
        "    old_col : str\n",
        "        Name of the column (sans \"_#\")\n",
        "    new_cols : list\n",
        "        New names to be given to the columns\n",
        "    '''\n",
        "    df.rename(columns={'{}_{}'.format(old_col, idx): new_col_name\n",
        "                       for idx, new_col_name in enumerate(new_cols)},\n",
        "              inplace=True\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TgtmSABI36S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quality_factor(data, M=2):\n",
        "    '''\n",
        "    Compute a quality factor for burst triggers.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : `numpy.ndarray`\n",
        "        One dimensional data array\n",
        "    M : int\n",
        "        Smoothing factor\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    Q : `numpy.ndarray`\n",
        "        Burst trigger quality factor\n",
        "    '''\n",
        "    smoothed_data = [data[0]]\n",
        "    for i, value in enumerate(data[1:]):\n",
        "        smoothed_data.append((smoothed_data[i - 1] * (2 ** M - 1) + value) / 2 ** M)\n",
        "    return np.subtract(data, smoothed_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFRH4TUI36U",
        "colab_type": "text"
      },
      "source": [
        "<a id='fgm_data'></a>\n",
        "### FGM Data\n",
        "Download the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMTFN8jiI36V",
        "colab_type": "code",
        "outputId": "e39e1221-c359-431a-e461-cce60e9e1e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# There are two magnetometers: AFG and DFG. For L2 data, AFG is\n",
        "# used for slow survey and DFG is used for fast survey, but are\n",
        "# known by the instrument name FGM. For SITL-level data, the\n",
        "# instruments are separate and named as AFG and DFG.\n",
        "afg_instr = 'afg'\n",
        "if level == 'l2':\n",
        "    afg_instr = 'fgm'\n",
        "\n",
        "afg_mode = mode\n",
        "\n",
        "# The \"SITL\"-level data for AFG is labeled \"ql\" for quick-look\n",
        "afg_level = level\n",
        "if level == 'sitl':\n",
        "    afg_level = 'ql'\n",
        "\n",
        "afg_optdesc = None\n",
        "\n",
        "# Download the data files\n",
        "mms.instr = afg_instr\n",
        "mms.mode = afg_mode\n",
        "mms.level = afg_level\n",
        "mms.optdesc = afg_optdesc\n",
        "afg_files = mms.download_files()\n",
        "print(*afg_files, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171001_v3.102.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171002_v3.102.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171003_v3.103.0.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171004_v3.103.2.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171005_v3.103.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171006_v3.103.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171007_v3.103.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171008_v3.103.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171009_v3.103.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171010_v3.103.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171011_v3.103.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171012_v3.104.0.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171013_v3.104.2.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171014_v3.104.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171015_v3.104.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171016_v3.104.2.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171017_v3.105.0.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171018_v3.105.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171019_v3.105.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171020_v3.105.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171021_v3.105.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171022_v3.105.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171023_v3.105.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171024_v3.106.0.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171025_v3.106.2.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171026_v3.106.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171027_v3.106.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171028_v3.106.3.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171029_v3.106.4.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171030_v3.106.1.cdf\n",
            "root/mms/data/mms1/afg/srvy/ql/2017/10/mms1_afg_srvy_ql_20171031_v3.107.0.cdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhosMsb2I36X",
        "colab_type": "text"
      },
      "source": [
        "Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCArpjUAI36X",
        "colab_type": "code",
        "outputId": "4a99ebff-8e1f-49d6-c822-7fc559266227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the variable names from a sample file\n",
        "afg_cdf = cdfread.CDF(afg_files[0])\n",
        "info = afg_cdf.cdf_info()\n",
        "afg_cdf.close()\n",
        "print(*info['zVariables'], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch\n",
            "mms1_afg_srvy_dmpa\n",
            "mms1_afg_srvy_gsm_dmpa\n",
            "label_b_dmpa\n",
            "label_b_gsm_dmpa\n",
            "Epoch_state\n",
            "label_r_gse\n",
            "label_r_gsm\n",
            "label_RADec_gse\n",
            "mms1_ql_pos_gse\n",
            "mms1_ql_pos_gsm\n",
            "mms1_ql_RADec_gse\n",
            "mms1_afg_srvy_ql_flag\n",
            "mms1_afg_srvy_ql_status\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcMUlJRsI36Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable names\n",
        "t_vname = 'Epoch'\n",
        "if afg_level == 'l2':\n",
        "    b_vname = '_'.join((sc, afg_instr, 'b', 'dmpa', afg_mode, afg_level))\n",
        "else:\n",
        "    b_vname = '_'.join((sc, afg_instr, afg_mode, 'dmpa'))\n",
        "\n",
        "# Read the data\n",
        "afg_df = read_cdf_vars(afg_files, b_vname, epoch=t_vname)\n",
        "\n",
        "# Rename variables\n",
        "rename_df_cols(afg_df, b_vname, ('Bx', 'By', 'Bz', '|B|'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAaIXCa9I36b",
        "colab_type": "text"
      },
      "source": [
        "Compute metafeatures and store data in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5kJyfdUI36c",
        "colab_type": "code",
        "outputId": "a8aec22d-02dc-491a-b81a-1ca65bfc983e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute metafeatures\n",
        "afg_df['P_B'] = afg_df['|B|']**2 / scipy.constants.mu_0\n",
        "afg_df['clock_angle'] = np.arctan2(afg_df['By'], afg_df['Bz'])\n",
        "afg_df['Q_dBx'] = quality_factor(afg_df['Bx'])\n",
        "afg_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bx</th>\n",
              "      <th>By</th>\n",
              "      <th>Bz</th>\n",
              "      <th>|B|</th>\n",
              "      <th>P_B</th>\n",
              "      <th>clock_angle</th>\n",
              "      <th>Q_dBx</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-10-01 00:00:01.241654</th>\n",
              "      <td>-5.002104</td>\n",
              "      <td>-5.471679</td>\n",
              "      <td>12.301073</td>\n",
              "      <td>14.362337</td>\n",
              "      <td>1.641498e+08</td>\n",
              "      <td>-0.418532</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-01 00:00:01.304155</th>\n",
              "      <td>-5.315543</td>\n",
              "      <td>-4.692515</td>\n",
              "      <td>12.419102</td>\n",
              "      <td>14.300657</td>\n",
              "      <td>1.627429e+08</td>\n",
              "      <td>-0.361264</td>\n",
              "      <td>-0.235080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-01 00:00:01.366656</th>\n",
              "      <td>-5.596068</td>\n",
              "      <td>-3.962622</td>\n",
              "      <td>12.667543</td>\n",
              "      <td>14.404340</td>\n",
              "      <td>1.651113e+08</td>\n",
              "      <td>-0.303174</td>\n",
              "      <td>-0.445473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-01 00:00:01.429157</th>\n",
              "      <td>-5.885676</td>\n",
              "      <td>-3.150924</td>\n",
              "      <td>12.924109</td>\n",
              "      <td>14.546549</td>\n",
              "      <td>1.683876e+08</td>\n",
              "      <td>-0.239137</td>\n",
              "      <td>-0.603909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-01 00:00:01.491657</th>\n",
              "      <td>-6.014797</td>\n",
              "      <td>-2.531629</td>\n",
              "      <td>13.607796</td>\n",
              "      <td>15.091687</td>\n",
              "      <td>1.812449e+08</td>\n",
              "      <td>-0.183940</td>\n",
              "      <td>-0.648152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Bx        By  ...  clock_angle     Q_dBx\n",
              "Epoch                                           ...                       \n",
              "2017-10-01 00:00:01.241654 -5.002104 -5.471679  ...    -0.418532  0.000000\n",
              "2017-10-01 00:00:01.304155 -5.315543 -4.692515  ...    -0.361264 -0.235080\n",
              "2017-10-01 00:00:01.366656 -5.596068 -3.962622  ...    -0.303174 -0.445473\n",
              "2017-10-01 00:00:01.429157 -5.885676 -3.150924  ...    -0.239137 -0.603909\n",
              "2017-10-01 00:00:01.491657 -6.014797 -2.531629  ...    -0.183940 -0.648152\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u71MP0KOI36e",
        "colab_type": "text"
      },
      "source": [
        "<a id='edp_data'></a>\n",
        "### EDP Data\n",
        "Download the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icMtCgHbI36e",
        "colab_type": "code",
        "outputId": "06e0fc7a-d631-4a1f-db13-348c5b248d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "edp_instr = 'edp'\n",
        "edp_optdesc = 'dce'\n",
        "\n",
        "# EDP does not have \"srvy\" data, just \"fast\" and \"slow\"\n",
        "edp_mode = mode\n",
        "if mode == 'srvy':\n",
        "    edp_mode = 'fast'\n",
        "\n",
        "# The \"SITL\"-level data for EDP is labeled \"ql\" for quick-look\n",
        "edp_level = level\n",
        "if level == 'sitl':\n",
        "    edp_level = 'ql'\n",
        "\n",
        "# Download the data files\n",
        "mms.instr = edp_instr\n",
        "mms.mode = edp_mode\n",
        "mms.optdesc = edp_optdesc\n",
        "edp_files = mms.download_files()\n",
        "print(*edp_files, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171001000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171002000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171003000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171004000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171005000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171006000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171007000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171008000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171009000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171010000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171011000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171012000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171013000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171014000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171015000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171016000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171017000000_v1.4.1.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171018000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171019000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171020000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171021000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171022000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171023000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171024000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171025000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171026000000_v1.4.2.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171027000000_v1.4.4.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171028000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171029000000_v1.4.3.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171030000000_v1.4.1.cdf\n",
            "root/mms/data/mms1/edp/fast/ql/dce/2017/10/mms1_edp_fast_ql_dce_20171031000000_v1.4.3.cdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jfwGBvzI36h",
        "colab_type": "text"
      },
      "source": [
        "Read the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7aEu1xI36h",
        "colab_type": "code",
        "outputId": "672493d7-d3cd-477c-8632-5fab89c39633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the variable names from a sample file\n",
        "edp_cdf = cdfread.CDF(edp_files[0])\n",
        "info = edp_cdf.cdf_info()\n",
        "edp_cdf.close()\n",
        "print(*info['zVariables'], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mms1_edp_dce_epoch\n",
            "DSL_Label\n",
            "FAC_Label\n",
            "ERR_Label\n",
            "RES_Label\n",
            "mms1_edp_dce_xyz_dsl\n",
            "mms1_edp_dce_xyz_fac\n",
            "mms1_edp_dce_xyz_err\n",
            "mms1_edp_dce_xyz_res_dsl\n",
            "mms1_edp_dce_bitmask\n",
            "mms1_edp_dce_quality\n",
            "mms1_edp_representation1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO_DqGsCI36j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable names\n",
        "if level == 'l2':\n",
        "    t_vname = '_'.join((sc, edp_instr, 'epoch', edp_mode, edp_level))\n",
        "    e_vname = '_'.join((sc, edp_instr, edp_optdesc, 'dsl', edp_mode, edp_level))\n",
        "else:\n",
        "    t_vname = '_'.join((sc, edp_instr, edp_optdesc, 'epoch'))\n",
        "    e_vname = '_'.join((sc, edp_instr, edp_optdesc, 'xyz', 'dsl'))\n",
        "\n",
        "# Read the data\n",
        "edp_df = read_cdf_vars(edp_files, e_vname, epoch=t_vname)\n",
        "\n",
        "# Rename variables\n",
        "new_vnames = ('Ex', 'Ey', 'Ez')\n",
        "edp_df.rename(columns={'{}_{}'.format(e_vname, idx): vname\n",
        "                       for idx, vname in enumerate(new_vnames)},\n",
        "              inplace=True\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfij9HBRI36m",
        "colab_type": "text"
      },
      "source": [
        "Compute metafeatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Romth98bI36n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edp_df['|E|'] = np.sqrt(edp_df['Ex']**2 + edp_df['Ey']**2 + edp_df['Ez']**2)\n",
        "edp_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGHzYMQ0I36p",
        "colab_type": "text"
      },
      "source": [
        "<a id='dis_data'></a>\n",
        "### DIS Data\n",
        "Download the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxzWbstAI36p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_instr = 'fpi'\n",
        "\n",
        "# FPI does not have \"srvy\" data, just \"fast\" and \"slow\"\n",
        "dis_mode = mode\n",
        "if mode == 'srvy':\n",
        "    dis_mode = 'fast'\n",
        "\n",
        "# The \"SITL\"-level data for FPI is labeled \"ql\" for quick-look\n",
        "# There is SITL-level data, but it was discontinued early in the mission\n",
        "dis_level = level\n",
        "if level == 'sitl':\n",
        "    dis_level = 'ql'\n",
        "\n",
        "dis_optdesc = 'dis'\n",
        "if level == 'l2':\n",
        "    dis_optdesc = 'dis-moms'\n",
        "\n",
        "# Download the data files\n",
        "mms.instr = dis_instr\n",
        "mms.mode = dis_mode\n",
        "mms.level = dis_level\n",
        "mms.optdesc = dis_optdesc\n",
        "dis_files = mms.download_files()\n",
        "print(*dis_files, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1gugI7VI36r",
        "colab_type": "text"
      },
      "source": [
        "Read the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-7lfOLsI36r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the variable names from a sample file\n",
        "dis_cdf = cdfread.CDF(dis_files[0])\n",
        "info = dis_cdf.cdf_info()\n",
        "print(*info['zVariables'], sep='\\n')\n",
        "\n",
        "# Print information about the pressure tensor\n",
        "# to figure out its dimensions and how the components\n",
        "# are stored\n",
        "vname = '_'.join((sc, 'dis', 'prestensor', 'dbcs', dis_mode))\n",
        "var_notes = dis_cdf.attget(attribute='VAR_NOTES', entry=vname)\n",
        "print(var_notes['Data'])\n",
        "\n",
        "# Close the file\n",
        "dis_cdf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xfCxfCoI36t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable names\n",
        "t_vname = 'Epoch'\n",
        "espectr_omni_vname = '_'.join((sc, 'dis', 'energyspectr', 'omni', dis_mode))\n",
        "n_vname = '_'.join((sc, 'dis', 'numberdensity', dis_mode))\n",
        "v_vname = '_'.join((sc, 'dis', 'bulkv', 'dbcs', dis_mode))\n",
        "q_heat_vname = '_'.join((sc, 'dis', 'heatq', 'dbcs', dis_mode))\n",
        "t_para_vname = '_'.join((sc, 'dis', 'temppara', dis_mode))\n",
        "t_perp_vname = '_'.join((sc, 'dis', 'tempperp', dis_mode))\n",
        "t_tens_vname = '_'.join((sc, 'dis', 'temptensor', 'dbcs', dis_mode))\n",
        "p_tens_vname = '_'.join((sc, 'dis', 'prestensor', 'dbcs', dis_mode))\n",
        "\n",
        "# Read the data\n",
        "dis_df = read_cdf_vars(dis_files,\n",
        "                       [espectr_omni_vname, n_vname, v_vname,\n",
        "                        q_heat_vname, t_para_vname, t_perp_vname,\n",
        "                        p_tens_vname, t_tens_vname\n",
        "                       ],\n",
        "                       epoch=t_vname\n",
        "                      )\n",
        "\n",
        "# Rename variables\n",
        "dis_df.rename(columns={n_vname: 'Ni'}, inplace=True)\n",
        "dis_df.rename(columns={t_para_vname: 'Ti_para'}, inplace=True)\n",
        "dis_df.rename(columns={t_perp_vname: 'Ti_perp'}, inplace=True)\n",
        "rename_df_cols(dis_df, v_vname, ('Vix', 'Viy', 'Viz'))\n",
        "rename_df_cols(dis_df, q_heat_vname, ('Qi_xx', 'Qi_yy', 'Qi_zz'))\n",
        "rename_df_cols(dis_df, t_tens_vname,\n",
        "               ('Ti_xx', 'Ti_xy', 'Ti_xz', 'Ti_yx', 'Ti_yy', 'Ti_yz', 'Ti_zx', 'Ti_zy', 'Ti_zz'))\n",
        "rename_df_cols(dis_df, p_tens_vname,\n",
        "               ('Pi_xx', 'Pi_xy', 'Pi_xz', 'Pi_yx', 'Pi_yy', 'Pi_yz', 'Pi_zx', 'Pi_zy', 'Pi_zz'))\n",
        "rename_df_cols(dis_df, espectr_omni_vname, ['especi_{0}'.format(idx) for idx in range(32)])\n",
        "\n",
        "# Drop redundant components of the pressure and temperature tensors\n",
        "dis_df.drop(columns=['Ti_xy', 'Ti_xz', 'Ti_yz', 'Pi_xy', 'Pi_xz', 'Pi_yz'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmlhnH4wI36v",
        "colab_type": "text"
      },
      "source": [
        "Compute metafeatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aKtvqNoDI36w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_df['Ti_anisotropy'] = (dis_df['Ti_para'] / dis_df['Ti_perp']) - 1\n",
        "dis_df['Ti_scalar'] = (dis_df['Ti_para'] + 2*dis_df['Ti_perp']) / 3.0\n",
        "dis_df['Q_dNi'] = quality_factor(dis_df['Ni'])\n",
        "dis_df['Q_dViz'] = quality_factor(dis_df['Viz'])\n",
        "Vi_mag = np.sqrt(dis_df['Vix']**2 + dis_df['Viy']**2 + dis_df['Viz']**2)\n",
        "Pi_ram = dis_df['Ni'] * Vi_mag\n",
        "dis_df['Q_dPi_ram'] = quality_factor(Pi_ram)\n",
        "\n",
        "# Drop features that were accidentally excluded\n",
        "dis_df.drop(columns=['especi_31', 'Viz', 'Qi_zz'], inplace=True)\n",
        "\n",
        "print(dis_df.columns)\n",
        "dis_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIch4ecNI36y",
        "colab_type": "text"
      },
      "source": [
        "<a id='des_data'></a>\n",
        "### DES Data\n",
        "Download the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVudYIVI36y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "des_instr = 'fpi'\n",
        "\n",
        "# FPI does not have \"srvy\" data, just \"fast\" and \"slow\"\n",
        "des_mode = mode\n",
        "if mode == 'srvy':\n",
        "    des_mode = 'fast'\n",
        "\n",
        "# The \"SITL\"-level data for FPI is labeled \"ql\" for quick-look\n",
        "# There is SITL-level data, but it was discontinued early in the mission\n",
        "des_level = level\n",
        "if level == 'sitl':\n",
        "    des_level = 'ql'\n",
        "\n",
        "des_optdesc = 'des'\n",
        "if level == 'l2':\n",
        "    des_optdesc = 'des-moms'\n",
        "\n",
        "# Download the data files\n",
        "mms.instr = des_instr\n",
        "mms.mode = des_mode\n",
        "mms.level = des_level\n",
        "mms.optdesc = des_optdesc\n",
        "des_files = mms.download_files()\n",
        "print(*des_files, sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tGHJbCSI361",
        "colab_type": "text"
      },
      "source": [
        "Read the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpLPeLaCI361",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the variable names from a sample file\n",
        "des_cdf = cdfread.CDF(des_files[0])\n",
        "info = des_cdf.cdf_info()\n",
        "print(*info['zVariables'], sep='\\n')\n",
        "\n",
        "# Print information about the pressure tensor\n",
        "# to figure out its dimensions and how the components\n",
        "# are stored\n",
        "vname = 'mms1_des_prestensor_dbcs_fast'\n",
        "var_notes = des_cdf.attget(attribute='VAR_NOTES', entry=vname)\n",
        "print(var_notes['Data'])\n",
        "\n",
        "# Close the file\n",
        "des_cdf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H52Vif81I364",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable names\n",
        "t_vname = 'Epoch'\n",
        "espectr_omni_vname = '_'.join((sc, 'des', 'energyspectr', 'omni', des_mode))\n",
        "n_vname = '_'.join((sc, 'des', 'numberdensity', des_mode))\n",
        "v_vname = '_'.join((sc, 'des', 'bulkv', 'dbcs', des_mode))\n",
        "q_heat_vname = '_'.join((sc, 'des', 'heatq', 'dbcs', des_mode))\n",
        "t_para_vname = '_'.join((sc, 'des', 'temppara', des_mode))\n",
        "t_perp_vname = '_'.join((sc, 'des', 'tempperp', des_mode))\n",
        "t_tens_vname = '_'.join((sc, 'des', 'temptensor', 'dbcs', des_mode))\n",
        "p_tens_vname = '_'.join((sc, 'des', 'prestensor', 'dbcs', des_mode))\n",
        "\n",
        "# Read the data\n",
        "des_df = read_cdf_vars(des_files,\n",
        "                       [espectr_omni_vname, n_vname, v_vname,\n",
        "                        q_heat_vname, t_para_vname, t_perp_vname,\n",
        "                        p_tens_vname, t_tens_vname\n",
        "                       ],\n",
        "                       epoch=t_vname\n",
        "                      )\n",
        "\n",
        "# Rename variables\n",
        "des_df.rename(columns={n_vname: 'Ne'}, inplace=True)\n",
        "des_df.rename(columns={t_para_vname: 'Te_para'}, inplace=True)\n",
        "des_df.rename(columns={t_perp_vname: 'Te_perp'}, inplace=True)\n",
        "rename_df_cols(des_df, v_vname, ('Vex', 'Vey', 'Vez'))\n",
        "rename_df_cols(des_df, q_heat_vname, ('Qe_xx', 'Qe_yy', 'Qe_zz'))\n",
        "rename_df_cols(des_df, t_tens_vname,\n",
        "               ('Te_xx', 'Te_xy', 'Te_xz', 'Te_yx', 'Te_yy', 'Te_yz', 'Te_zx', 'Te_zy', 'Te_zz'))\n",
        "rename_df_cols(des_df, p_tens_vname,\n",
        "               ('Pe_xx', 'Pe_xy', 'Pe_xz', 'Pe_yx', 'Pe_yy', 'Pe_yz', 'Pe_zx', 'Pe_zy', 'Pe_zz'))\n",
        "rename_df_cols(des_df, espectr_omni_vname, ['espece_{0}'.format(idx) for idx in range(32)])\n",
        "\n",
        "# Drop symmetric, redundant components\n",
        "des_df.drop(columns=['Te_xy', 'Te_xz', 'Te_yz', 'Pe_xy', 'Pe_xz', 'Pe_yz'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9equpgH-I366",
        "colab_type": "text"
      },
      "source": [
        "Compute metafeatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NOLZIPJ4I366",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "des_df['Te_anisotropy'] = (des_df['Te_para'] / des_df['Te_perp']) - 1\n",
        "des_df['Te_scalar'] = (des_df['Te_para'] + 2*des_df['Te_perp']) / 3.0\n",
        "des_df['Pe_scalar'] = (des_df['Pe_xx'] + des_df['Pe_yy'] + des_df['Pe_zz']) / 3.0\n",
        "des_df['Q_dNe'] = quality_factor(des_df['Ne'])\n",
        "des_df['Q_dVez'] = quality_factor(des_df['Vez'])\n",
        "#Ve_mag = np.sqrt(des_df['Vex']**2 + des_df['Vey']**2 + des_df['Vez']**2)\n",
        "#Pe_ram = des_df['Ne'] * Ve_mag\n",
        "#des_df['Q_dPe_ram'] = quality_factor(Pe_ram)\n",
        "\n",
        "\n",
        "# Drop features that were accidentally excluded\n",
        "des_df.drop(columns=['espece_31', 'Vez', 'Qe_zz'], inplace=True)\n",
        "\n",
        "print(des_df.columns)\n",
        "des_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooRdsANuI368",
        "colab_type": "text"
      },
      "source": [
        "<a id='combine_dataframes'></a>\n",
        "### Combine DataFrames and Compute Additional Metafeatures\n",
        "Now we will combine all dataframes, downsampling to DES, which as the time index with the longest sampling period (`4.5s`). After that, multi-instrument metafeatures are calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "683QZA-DI368",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resample data\n",
        "afg_df = afg_df.reindex(des_df.index, method='nearest')\n",
        "edp_df = edp_df.reindex(des_df.index, method='nearest')\n",
        "dis_df = dis_df.reindex(des_df.index, method='nearest')\n",
        "\n",
        "# Merge dataframes\n",
        "df = des_df\n",
        "df = df.join(dis_df, how='outer')\n",
        "df = df.join(afg_df, how='outer')\n",
        "df = df.join(edp_df, how='outer')\n",
        "\n",
        "# Metafeatures\n",
        "df['T_ratio'] = df['Ti_scalar'] / df['Ti_scalar']\n",
        "df['plasma_beta'] = (df['Ti_scalar'] + df['Ti_scalar']) / df['|E|']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vctUwOYNI36-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(*df.columns, sep=', ')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFTOnvNaI37A",
        "colab_type": "text"
      },
      "source": [
        "<a id='run_model'></a>\n",
        "## Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8lQ-rHTI37A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roundTime(dt=None, dateDelta=datetime.timedelta(minutes=1)):\n",
        "    \"\"\"Round a datetime object to a multiple of a timedelta\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dt : `datetime.datetime` = datetime.datetime.now().\n",
        "    dateDelta : `datetime.timedelta`\n",
        "        we round to a multiple of this, default 1 minute.\n",
        "    \n",
        "    Author: Thierry Husson 2012 - Use it as you want but don't blame me.\n",
        "            Stijn Nevens 2014 - Changed to use only datetime objects as variables\n",
        "    \"\"\"\n",
        "    roundTo = dateDelta.total_seconds()\n",
        "\n",
        "    if dt == None : dt = datetime.datetime.now()\n",
        "    seconds = (dt.to_pydatetime() - dt.to_pydatetime().min).seconds\n",
        "    # // is a floor division, not a comment on following line:\n",
        "    rounding = (seconds+roundTo/2) // roundTo * roundTo\n",
        "    return dt + datetime.timedelta(0,rounding-seconds,-dt.microsecond)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIxOe82I37D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm(num_features=123, layer_size=300):\n",
        "    \"\"\"\n",
        "    Helper function to define the LSTM used to make predictions.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(LSTM(layer_size, return_sequences=True, activation='tanh', recurrent_activation='sigmoid'),\n",
        "                            input_shape=(None, num_features)))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(layer_size, return_sequences=True, activation='tanh', recurrent_activation='sigmoid')))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK-H6UYlI37F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define MMS CDF directory location\n",
        "# Load model\n",
        "model = lstm()\n",
        "model.load_weights(str(model_root / 'model_weights.h5'))\n",
        "\n",
        "# Interpolate interior values, drop outside rows containing 0s\n",
        "data = df.replace([np.inf, -np.inf], np.nan)\n",
        "data = data.interpolate(method='time', limit_area='inside')\n",
        "data = data.loc[(df != 0).any(axis=1)]\n",
        "\n",
        "# Select data within time range\n",
        "data = data.loc[start_date:end_date]\n",
        "data_index = data.index\n",
        "\n",
        "# Scale data\n",
        "scaler = pickle.load(open(model_root / 'scaler.sav', 'rb'))\n",
        "data = scaler.transform(data)\n",
        "\n",
        "# Run data through model\n",
        "predictions_list = model.predict(np.expand_dims(data, axis=0))\n",
        "\n",
        "# Filter predictions with threshold\n",
        "threshold = 0.5\n",
        "filtered_output = [0 if x < threshold else 1 for x in predictions_list.squeeze()]\n",
        "\n",
        "# Create selections from predictions\n",
        "predictions_df = pd.DataFrame()\n",
        "predictions_df.insert(0, \"time\", data_index)\n",
        "predictions_df.insert(1, \"prediction\", filtered_output)\n",
        "predictions_df['group'] = (predictions_df.prediction != predictions_df.prediction.shift()).cumsum()\n",
        "predictions_df = predictions_df.loc[predictions_df['prediction'] == 1]\n",
        "selections = pd.DataFrame({'BeginDate': predictions_df.groupby('group').time.first().map(lambda x: roundTime(utc2tai(x), datetime.timedelta(seconds=10))),\n",
        "                           'EndDate': predictions_df.groupby('group').time.last().map(lambda x: roundTime(utc2tai(x), datetime.timedelta(seconds=10)))})\n",
        "selections = selections.set_index('BeginDate')\n",
        "\n",
        "selections['score'] = \"150.0\" # This is a placeholder for the FOM\n",
        "selections['description'] = \"MP crossing (automatically generated)\"\n",
        "\n",
        "# Create the file name: gls_selections_<model-name>_<current-time-as-YYYY-MM-DD-HH-MM-SS>.csv\n",
        "current_datetime = datetime.datetime.now()\n",
        "selections_filetime = current_datetime.strftime('%Y-%m-%d-%H-%M-%S')\n",
        "file_name = 'gls_selections_mp-dl-unh_{0}.csv'.format(selections_filetime)\n",
        "\n",
        "# Output selections\n",
        "print('Saving selections to CSV: {0}'.format(file_name))\n",
        "if not dropbox_root.exists():\n",
        "    dropbox_root.mkdir(parents=True)\n",
        "selections.to_csv(dropbox_root / file_name, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72-j7YYCI37G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/root/mms/data/mms1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7kt9V4Up5Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}